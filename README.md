# On-Prem to Azure Cloud Migration for Airline Data Platform using ADF, PySpark & Delta Lake

Successfully completed an end-to-end **on-premises to Azure cloud data migration** project for an **airline analytics platform** using **Azure Data Factory (ADF)**, **PySpark**, and **Delta Lake**, following the **Medallion Architecture**.

<img width="1280" height="640" alt="Architecture" src="https://github.com/user-attachments/assets/d851de1c-909b-4288-9c6d-8f98eab0eaf8" />

## 🔍 Key Highlights:

- ✅ Migrated structured and semi-structured datasets (`.csv` and `.json`) from on-prem sources to **Azure Data Lake**
- 🔄 Built **dynamic, parameterized ADF pipelines** for scalable and reusable ETL workflows
- 🧊 Used **PySpark and Mapping Data Flows** for transformation logic within ADF
- 🔁 Integrated third-party **APIs and Logic Apps** for real-time data ingestion
- 🛢️ Modeled a **Lakehouse architecture** (Bronze → Silver → Gold layers) using **Delta Lake**
- ⚙️ Implemented **CI/CD with Azure DevOps and GitHub** for version control and deployment
- ⏱️ Set up **trigger-based orchestration** and **incremental data loading**

---

## 🛠️ Tools & Technologies:
`Azure Data Factory` | `PySpark` | `Delta Lake` | `Azure SQL DB` | `Logic Apps` | `Azure DevOps` | `GitHub` | `Medallion Architecture`

---

## 📁 Datasets Used:
- `DimAirline.csv`
- `DimPassenger.csv`
- `DimFlight.csv`
- `FactBookings.csv`
- `DimAirport.json`
