# On-Prem to Azure Cloud Migration for Airline Data Platform using ADF, PySpark & Delta Lake

Successfully completed an end-to-end **on-premises to Azure cloud data migration** project for an **airline analytics platform** using **Azure Data Factory (ADF)**, **PySpark**, and **Delta Lake**, following the **Medallion Architecture**.

<img width="1280" height="640" alt="Architecture" src="https://github.com/user-attachments/assets/d851de1c-909b-4288-9c6d-8f98eab0eaf8" />

## ğŸ” Key Highlights:

- âœ… Migrated structured and semi-structured datasets (`.csv` and `.json`) from on-prem sources to **Azure Data Lake**
- ğŸ”„ Built **dynamic, parameterized ADF pipelines** for scalable and reusable ETL workflows
- ğŸ§Š Used **PySpark and Mapping Data Flows** for transformation logic within ADF
- ğŸ” Integrated third-party **APIs and Logic Apps** for real-time data ingestion
- ğŸ›¢ï¸ Modeled a **Lakehouse architecture** (Bronze â†’ Silver â†’ Gold layers) using **Delta Lake**
- âš™ï¸ Implemented **CI/CD with Azure DevOps and GitHub** for version control and deployment
- â±ï¸ Set up **trigger-based orchestration** and **incremental data loading**

---

## ğŸ› ï¸ Tools & Technologies:
`Azure Data Factory` | `PySpark` | `Delta Lake` | `Azure SQL DB` | `Logic Apps` | `Azure DevOps` | `GitHub` | `Medallion Architecture`

---

## ğŸ“ Datasets Used:
- `DimAirline.csv`
- `DimPassenger.csv`
- `DimFlight.csv`
- `FactBookings.csv`
- `DimAirport.json`
